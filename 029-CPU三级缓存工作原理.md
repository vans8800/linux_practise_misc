在现代计算机系统中，CPU 的运算速度远超内存的访问速度。

为了解决这个问题，CPU缓存应运而生。如何理解CPU的效率高于内存的效率？本身CPU处理数据，而内存存储数据，如何比较速度？先来看一张图，这个图可以比较清楚地看到CPU的主要构成及其与主内存的关系。

<img width="904" height="486" alt="image" src="https://github.com/user-attachments/assets/47daa7a9-c8a1-4dd3-aa3f-999a6ec9b4d0" />

从上图中可以看出，CPU由多个部分组成，其中包含了算术逻辑单元ALU，控制单元CU，内存管理单元MMU，寄存器register，程序计数器PC，以及今天的主角缓存cache。

其中距离ALU最近的存储结构就是寄存器。所以若没有缓存，那么这时候应该比较的就是ALU从寄存器中读取数据的速度与读取主内存的速度。

## 缓存的作用
---

外存像出版社，内存像图书馆，而缓存就像手边的书架。我们需要看书时，肯定先看书架上有没有，没有再去图书馆，图书馆也没有才去找出版社。

CPU 也是这样工作的：它先查缓存（L1 → L2 → L3），查到了就称为“命中”，直接处理；如果都查不到，才去内存找。

<img width="1080" height="415" alt="image" src="https://github.com/user-attachments/assets/75b9a7c0-c02a-4a31-a9c8-2e5c0188a00a" />


如此，CPU的运行效率就会快很多。

因为缓存比内存小。所以很快就可以搜索一遍。而在三级缓存中，L1<L2<L3，所以距离CPU越近的存储结构，存储空间越小。

在计算机学科的概念中，局部性原理分为时间局部性原理和空间局部性原理。

- 时间局部性：如果一个数据正在被访问，那么在近期它很可能还会被再次访问。

- 空间局部性：在不久的将来将用到的数据很可能与现在正在使用的数据在空间地址上是临近的。

## 三级缓存
---

缓存存在于内核和主内存中间，总共分为三级（一般情况）：

- L1 Cache： 在 CPU 核心内部，分为指令缓存和数据缓存，分开存放 CPU 使用的指令和数据；

- L2 Cache： 在 CPU 核心内部，尺寸比 L1 更大；

- L3 Cache： 在 CPU 核心外部，所有 CPU 核心共享同一个 L3 缓存。

<img width="1080" height="391" alt="image" src="https://github.com/user-attachments/assets/3274510e-26ed-435a-82d7-d0ea78dfc5e4" />

缓存的存储空间较小，除高效的要求外，还有高制造成本的需求，一般缓存是由SRAM的存储单元构成的，而主内存是由DRAM存储单元构成的。

SRAM的储存单元成本要比DRAM高很多，为读写高效，SRAM每个存储单元由6个晶体管构成，而DRAM每个存储单元只需要1个晶体管和1个电容器。

## 存储的金字塔结构
---

<img width="1080" height="642" alt="image" src="https://github.com/user-attachments/assets/9737431b-e22a-47e1-bec1-5f117faca960" />

计算机的存储系统通常呈金字塔结构，从上到下包括：

- CPU 寄存器：速度最快，容量最小，直接参与运算。

- CPU 高速缓存（Cache）：位于 CPU 和内存之间，分为 L1、L2、L3 三级，速度快于内存，容量小于内存。

- 主存（RAM）：容量大，速度较慢，用于存储正在运行的程序和数据。

- 硬盘存储：容量最大，速度最慢，用于长期存储数据。这种结构旨在在速度、容量和成本之间取得平衡。

## 缓存的工作机制
---

当 CPU 需要访问数据时，按照以下顺序查找:

<img width="1080" height="1080" alt="image" src="https://github.com/user-attachments/assets/93b1d1ec-4ef6-40ec-aed1-c65c6798d945" />

L1 Cache：如果命中，直接读取；否则，查找 L2。

L2 Cache：如果命中，将数据加载到 L1，并读取；否则，查找 L3。

L3 Cache：如果命中，将数据加载到 L2 和 L1，并读取；否则，从主存中读取数据，并依次加载到各级缓存。

这种机制确保了数据访问的高效性，减少了对主存的访问次数。

## 缓存一致性与MESI协议
---

<img width="1080" height="1119" alt="image" src="https://github.com/user-attachments/assets/1fffb888-b234-4548-ba7e-ae5f60bf1763" />

在多核处理器中，每个核心有自己的 L1 和 L2 缓存，可能会出现多个缓存中存有相同数据副本的情况。

为保持数据一致性，采用了 MESI 协议，将缓存行的状态分为：

- Modified（已修改）：缓存中的数据已被修改，主存中为旧数据。

- Exclusive（独占）：缓存中的数据与主存一致，且只有该缓存拥有此数据。

- Shared（共享）：多个缓存中有相同的数据副本，数据与主存一致。

- Invalid（无效）：缓存中的数据无效。

通过 MESI 协议，确保了多核处理器中缓存数据的一致性。

MESI协议工作原理示意图:

<img width="1080" height="973" alt="image" src="https://github.com/user-attachments/assets/c1b2a2f8-2f38-4410-84d2-9a655d337951" />

